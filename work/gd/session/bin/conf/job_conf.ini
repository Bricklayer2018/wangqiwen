[global]
#input_ready should begin with "/", if it begins with "${output}", should not has "/"
# input_path_* & input_ready_*
retry_interval = 2
#-------------192--------------
#hadoop_client = /home/cpr/bin/hadoop/bin/hadoop
#hive_client = /home/cpr/bin/hadoop/bin/hive
#hadoop_client = /home/devuse/bin/hadoop/bin/hadoop
#hive_client = /home/devuse/bin/hadoop/bin/hive
#------------server217------------
#hadoop_client = /opt/cloudera/parcels/CDH-4.2.1-1.cdh4.2.1.p0.5/bin/hadoop
#hive_client = /data/soft/hadoop2/hive/bin/hive
#-------------online-------------
hadoop_client = /opt/hadoop/CDH-4.2.1-1.cdh4.2.1.p0.5/bin/hadoop
hive_client = /opt/hadoop/CDH-4.2.1-1.cdh4.2.1.p0.5/bin/hive

output_path = /user/hive/warehouse
database = log_session
mail_alarm = on
#mail_receiver_in = warren@autonavi.com,randy@autonavi.com,jeff@autonavi.com,kerui.ji@autonavi.com,clay@autonavi.com,huo.zhu@autonavi.com,weiwei.chen@autonavi.com,wei.min@autonavi.com,garnett@autonavi.com
mail_receiver_in = warren@autonavi.com
mail_receiver_out = warren@autonavi.com
msg_alarm = off
msg_receiver = 15210923792
diff_on = on
#==============================================
root_code_path = ./
re_run_number=3


[job_sp]
job_name = log_sp
input_ready_sp = /user/ops/flume/sp/sp_logger/${date1}
#input_ready_sp = /user/ops/flume/sp/sp_logger/old/${date2}
output_ready = ${output_path}/${database}.db/${job_name}/ready_${date}.done
code_path = hive_jobs/log/${job_name}/start_job.sh
#code_path = hive_jobs/log/${job_name}/old_start_job.sh
detect_start_time = 02:00
detect_end_time = 14:00
delay_before_start = 0
# 2014-5-21
diff_min_size = 0.05


[job_sptuan]
job_name = log_sptuan
input_ready_sp = /user/ops/flume/sp/sp_tuan/${date1}
output_ready = ${output_path}/${database}.db/${job_name}/ready_${date}.done
code_path = hive_jobs/log/${job_name}/start_job.sh
detect_start_time = 02:00
detect_end_time = 14:00
delay_before_start = 0
diff_min_size = 0.05

[job_spmovie]
job_name = log_spmovie
input_ready_sp = /user/ops/flume/sp/sp_movie/${date1}
output_ready = ${output_path}/${database}.db/${job_name}/ready_${date}.done
code_path = hive_jobs/log/${job_name}/start_job.sh
detect_start_time = 02:00
detect_end_time = 14:00
delay_before_start = 0
#diff_min_size = 0.01

[job_client]
job_name = log_client
#input_ready_client = /user/amap/data/mysql/bi/ods/page/ods_page_pagelog/${date1}/_SUCCESS
input_ready_client = /user/ops/flume/aos_page/${date1}
output_ready = ${output_path}/${database}.db/${job_name}/ready_${date}.done
code_path = hive_jobs/log/${job_name}/start_job.sh
detect_start_time = 01:00
detect_end_time = 20:00
delay_before_start = 0
# 2014-5-21
diff_min_size = 0.05

[job_client_rest]
# 2014-6-21
job_name = log_client_rest
input_ready_client =  ${output_path}/${database}.db/log_client/ready_${date}.done
output_ready = ${output_path}/${database}.db/${job_name}/ready_${date}.done
code_path = hive_jobs/log/log_client/split_start_job.sh
detect_start_time = 02:00
detect_end_time = 21:00
delay_before_start = 0


[job_aos_sns]
job_name = log_aos
input_ready_aos_sns = /user/ops/flume/aos_sns/${date1}
# 2014-9-09
input_ready_aos = /user/ops/flume/aos/aos_dxp/${date1}/23/45
output_ready = ${output_path}/${database}.db/${job_name}/ready_${date}.done
code_path = hive_jobs/log/${job_name}/start_job.sh
#code_path = hive_jobs/log/${job_name}/old_start_job.sh
detect_start_time = 02:10
detect_end_time = 20:00
delay_before_start = 0
# 2014-5-21
diff_min_size = 0.05


[job_sug]
job_name = log_sug
# 2014-10-22 ftp->flume
input_ready_sug = /user/ops/flume/sug/${date1}
# 2014-6-30
#input_ready_sug = /user/ops/flume/sug/old/${date}
output_ready = ${output_path}/${database}.db/${job_name}/ready_${date}.done
code_path = hive_jobs/log/${job_name}/start_job.sh
#code_path = hive_jobs/log/${job_name}/old_start_job.sh
#detect_start_time = 09:00
detect_start_time = 02:40
detect_end_time = 20:00
delay_before_start = 0
diff_min_size = 0.05


[job_merge]
job_name = log_merge
input_ready_sp =  ${output_path}/${database}.db/log_sp/ready_${date}.done
input_ready_sptuan =  ${output_path}/${database}.db/log_sptuan/ready_${date}.done
input_ready_spmovie =  ${output_path}/${database}.db/log_spmovie/ready_${date}.done
input_ready_client =  ${output_path}/${database}.db/log_client/ready_${date}.done
input_ready_aos =  ${output_path}/${database}.db/log_aos/ready_${date}.done
input_ready_sug =  ${output_path}/${database}.db/log_sug/ready_${date}.done
output_ready = ${output_path}/${database}.db/${job_name}/ready_${date}.done
code_path = hive_jobs/log/${job_name}/start_job.sh
must_input = sp&client&aos&sug&sptuan
detect_start_time = 04:00
detect_end_time = 21:00
delay_before_start = 0
#delay_before_start = 20

[job_mergeall]
job_name = log_mergeall
input_ready_sp =  ${output_path}/${database}.db/log_sp/ready_${date_pre}.done
input_ready_sptuan =  ${output_path}/${database}.db/log_sptuan/ready_${date_pre}.done
input_ready_spmovie =  ${output_path}/${database}.db/log_spmovie/ready_${date_pre}.done
input_ready_client =  ${output_path}/${database}.db/log_client/ready_${date_pre}.done
input_ready_clientsuf =  ${output_path}/${database}.db/log_client/ready_${date}.done
input_ready_aos =  ${output_path}/${database}.db/log_aos/ready_${date_pre}.done
input_ready_sug =  ${output_path}/${database}.db/log_sug/ready_${date_pre}.done
output_ready = ${output_path}/${database}.db/${job_name}/ready_${date_pre}.done
code_path = hive_jobs/log/${job_name}/start_job.sh
must_input = sp&client&aos&sug&sptuan&clientsuf
detect_start_time = 04:00
detect_end_time = 21:00
delay_before_start = 0

#================topic================
[job_query_click]
# 2014-6-3
job_name = query_click
input_ready_sp =  ${output_path}/${database}.db/log_sp/ready_${date}.done
input_ready_aos =  ${output_path}/${database}.db/log_aos/ready_${date}.done
output_ready = ${output_path}/${database}.db/${job_name}/ready_${date}.done
code_path = hive_jobs/topic/${job_name}/start_job.sh
detect_start_time = 03:30
detect_end_time = 21:00
delay_before_start = 0
diff_min_size = 0.01
must_input = sp&aos

[job_sug_click]
# 2014-6-24
job_name = sug_click
input_ready_sp =  ${output_path}/${database}.db/log_sp/ready_${date}.done
input_ready_sug =  ${output_path}/${database}.db/log_sug/ready_${date}.done
output_ready = ${output_path}/${database}.db/${job_name}/ready_${date}.done
code_path = hive_jobs/topic/${job_name}/start_job.sh
detect_start_time = 03:30
detect_end_time = 21:00
delay_before_start = 0
diff_min_size = 0.01
must_input = sp&sug


[job_client_click]
# 2014-8-19
job_name = client_click
input_ready_client = /user/ops/flume/aos_page/${date1}
input_ready_sp =  ${output_path}/${database}.db/log_sp/ready_${date}.done
output_ready = ${output_path}/${database}.db/${job_name}/ready_${date}.done
code_path = hive_jobs/topic/${job_name}/start_job.sh
detect_start_time = 03:30
detect_end_time = 21:00
delay_before_start = 0
#diff_min_size = 0.01
must_input= client&sp


#================stat================
[job_stat_query_click]
# 2014-6-6
job_name = stat_query_click
input_ready_click =  ${output_path}/${database}.db/query_click/ready_${date}.done
output_ready = ${output_path}/log_data.db/${job_name}/ready_${date}.done
code_path = hive_jobs/stat/${job_name}/start_job.sh
detect_start_time = 04:30
detect_end_time = 22:00
delay_before_start = 0

[job_stat_size]
# 2014-6-12
job_name = stat_size
input_ready_merge =  ${output_path}/${database}.db/log_merge/ready_${date}.done
output_ready = ${output_path}/log_data.db/${job_name}/ready_${date}.done
code_path = hive_jobs/stat/${job_name}/start_job.sh
detect_start_time = 04:00
detect_end_time = 22:00
delay_before_start = 0

[job_stat_sp_time]
# 2014-6-16
job_name = stat_sp_time
input_ready_sp =  ${output_path}/${database}.db/log_aos/ready_${date}.done
output_ready = ${output_path}/log_data.db/${job_name}/ready_${date}.done
code_path = hive_jobs/stat/${job_name}/start_job.sh
detect_start_time = 09:00
detect_end_time = 22:00
delay_before_start = 0

[job_stat_all_query]
# 2014-6-16
job_name = stat_all_query
input_ready_sp =  ${output_path}/${database}.db/log_sp/ready_${date}.done
output_ready = ${output_path}/log_data.db/${job_name}/ready_${date}.done
code_path = hive_jobs/stat/${job_name}/start_job.sh
detect_start_time = 07:00
detect_end_time = 22:00
delay_before_start = 0

[job_stat_monitor]
# 2014-7-03
job_name = stat_monitor
input_ready_merge =  ${output_path}/${database}.db/log_merge/ready_${date}.done
output_ready = ${output_path}/log_data.db/${job_name}/ready_${date}.done
code_path = hive_jobs/stat/${job_name}/start_job.sh
detect_start_time = 05:00
detect_end_time = 22:00
delay_before_start = 0

[job_stat_source]
# 2014-10-14 sp,sug flume\ftp
job_name = stat_source
input_ready_sp_flume = /user/ops/flume/sp/sp_logger/${date1}
input_ready_sp_ftp = /user/ops/flume/sp/sp_logger/old/${date2}
input_ready_sug_flume = /user/ops/flume/sug/${date1}
input_ready_sug_ftp = /user/ops/flume/sug/old/${date}
output_ready = ${output_path}/log_data.db/${job_name}/ready_${date}.done
code_path = hive_jobs/stat/${job_name}/start_job.sh
detect_start_time = 08:00
detect_end_time = 22:00
delay_before_start = 0

